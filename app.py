import streamlit as st
import cv2
import numpy as np
from PIL import Image
import pandas as pd
from datetime import datetime
import random
import logging
import os
from io import BytesIO

# ----------------- åˆå§‹åŒ–è®¾ç½® -----------------
st.set_page_config(
    page_title="AI Emotion & Location Detector",
    page_icon="ğŸŒ",
    layout="wide",
    initial_sidebar_state="expanded"
)

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ----------------- å¤šè¯­è¨€æ”¯æŒ -----------------
LANGUAGES = ["ä¸­æ–‡", "English", "Malay"]
lang = st.sidebar.selectbox("ğŸŒ Select Language / é€‰æ‹©è¯­è¨€ / Pilih Bahasa", LANGUAGES)

TRANSLATIONS = {
    "ä¸­æ–‡": {
        "title": "AIæƒ…ç»ªä¸ä½ç½®æ£€æµ‹ç³»ç»Ÿ",
        "upload_guide": "ä¸Šä¼ ç…§ç‰‡åˆ†æé¢éƒ¨è¡¨æƒ…å¹¶æ¨æµ‹ä½ç½®",
        "username": "ç”¨æˆ·å",
        "user_auth": "ç”¨æˆ·è®¤è¯",  # æ–°å¢
        "enter_username": "è¾“å…¥ç”¨æˆ·å",
        "welcome": "æ¬¢è¿",
        "upload_image": "ä¸Šä¼ å›¾ç‰‡ (JPG/PNG)",
        "analysis_results": "åˆ†æç»“æœ",
        "detected_emotion": "æ£€æµ‹åˆ°çš„æƒ…ç»ª",
        "estimated_location": "ä¼°è®¡ä½ç½®",
        "download_results": "ä¸‹è½½ç»“æœ",
        "original_image": "åŸå§‹å›¾ç‰‡",
        "processed_image": "å¤„ç†åçš„å›¾ç‰‡",
        "no_faces": "æœªæ£€æµ‹åˆ°äººè„¸",
        "error_processing": "å›¾ç‰‡å¤„ç†é”™è¯¯",
        "debug_info": "è°ƒè¯•ä¿¡æ¯",
        "input_username_continue": "è¯·è¾“å…¥ç”¨æˆ·åç»§ç»­"
    },
    "English": {
        "title": "AI Emotion & Location Detector",
        "upload_guide": "Upload a photo to analyze facial expressions and estimate location",
        "username": "Username",
        "user_auth": "User Authentication",  # æ–°å¢
        "enter_username": "Enter your username",
        "welcome": "Welcome",
        "upload_image": "Upload an image (JPG/PNG)",
        "analysis_results": "Analysis Results",
        "detected_emotion": "Detected Emotion",
        "estimated_location": "Estimated Location",
        "download_results": "Download Results",
        "original_image": "Original Image",
        "processed_image": "Processed Image",
        "no_faces": "No faces detected",
        "error_processing": "Error processing image",
        "debug_info": "Debug Info",
        "input_username_continue": "Please enter a username to continue"
    },
    "Malay": {
        "title": "Sistem Pengesanan Emosi & Lokasi AI",
        "upload_guide": "Muat naik foto untuk analisis ekspresi muka dan anggaran lokasi",
        "username": "Nama pengguna",
        "user_auth": "Pengesahan Pengguna",  # æ–°å¢
        "enter_username": "Masukkan nama pengguna",
        "welcome": "Selamat datang",
        "upload_image": "Muat naik imej (JPG/PNG)",
        "analysis_results": "Keputusan Analisis",
        "detected_emotion": "Emosi yang Dikesan",
        "estimated_location": "Lokasi Dianggarkan",
        "download_results": "Muat Turun Keputusan",
        "original_image": "Imej Asal",
        "processed_image": "Imej Diproses",
        "no_faces": "Tiada muka dikesan",
        "error_processing": "Ralat memproses imej",
        "debug_info": "Maklumat Debug",
        "input_username_continue": "Masukkan nama pengguna untuk meneruskan"
    }
}
T = TRANSLATIONS[lang]

# ----------------- åŠ è½½æ¨¡å‹ -----------------
@st.cache_resource
def load_face_cascade():
    try:
        # ä½¿ç”¨OpenCVè‡ªå¸¦çš„æ¨¡å‹è·¯å¾„
        model_path = cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"Model file not found at {model_path}")
        
        cascade = cv2.CascadeClassifier(model_path)
        if cascade.empty():
            raise ValueError("Failed to load cascade classifier")
        
        return cascade
    except Exception as e:
        logger.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        st.error("Failed to load face detection model")
        return None

# ----------------- æ ¸å¿ƒåŠŸèƒ½ -----------------
def detect_faces(img_cv, face_cascade):
    try:
        gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)
        faces = face_cascade.detectMultiScale(gray, 1.1, 4)
        return faces if faces is not None else np.array([])
    except Exception as e:
        logger.error(f"äººè„¸æ£€æµ‹é”™è¯¯: {e}")
        return np.array([])

def analyze_emotion(faces):
    return ["happy" if random.random() > 0.5 else "neutral" for _ in faces]

def draw_detections(img, faces, emotions):
    """ç»˜åˆ¶æ£€æµ‹æ¡†å’Œæƒ…ç»ªæ ‡ç­¾"""
    img_copy = img.copy()
    color_map = {
        "happy": (0, 255, 0),    # ç»¿è‰²
        "neutral": (255, 255, 0), # é»„è‰²
        "sad": (0, 0, 255),       # çº¢è‰²
        "angry": (0, 165, 255)    # æ©™è‰²
    }
    
    for i, ((x, y, w, h), emotion) in enumerate(zip(faces, emotions)):
        color = color_map.get(emotion, (255, 255, 255))
        cv2.rectangle(img_copy, (x, y), (x+w, y+h), color, 2)
        cv2.putText(img_copy, emotion, (x, y-10), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)
    return img_copy

def save_to_history(username, emotion, location):
    try:
        new_record = pd.DataFrame([{
            "username": username,
            "emotion": emotion,
            "location": location,
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }])
        
        if os.path.exists("history.csv"):
            history = pd.read_csv("history.csv")
            history = pd.concat([history, new_record])
        else:
            history = new_record
            
        history.to_csv("history.csv", index=False)
    except Exception as e:
        logger.error(f"ä¿å­˜å†å²è®°å½•å¤±è´¥: {e}")

# ----------------- æ˜¾ç¤ºåˆ†æç»“æœ -----------------
def show_analysis_results(uploaded_file, username, face_cascade):
    try:
        img = Image.open(uploaded_file)
        img_cv = np.array(img.convert("RGB"))

        col1, col2 = st.columns([1, 2])

        with col1:
            st.subheader(T["analysis_results"])

            faces = detect_faces(img_cv, face_cascade)
            if len(faces) == 0:
                st.warning(T["no_faces"])
                return

            emotions = analyze_emotion(faces)
            location = "Unknown"  # ç®€åŒ–ç‰ˆï¼Œä¸ä½¿ç”¨geopy

            st.metric(T["detected_emotion"], ", ".join(emotions))
            st.metric(T["estimated_location"], location)

            save_to_history(username, emotions[0], location)

            csv_data = pd.DataFrame({
                "Emotion": emotions,
                "Location": [location]*len(emotions)
            }).to_csv(index=False)
            
            st.download_button(
                label=T["download_results"],
                data=csv_data,
                file_name="analysis_results.csv"
            )

        with col2:
            tab1, tab2 = st.tabs([T["original_image"], T["processed_image"]])
            with tab1:
                st.image(img, use_column_width=True)
            with tab2:
                detected_img = draw_detections(img_cv, faces, emotions)
                st.image(detected_img, channels="BGR", use_column_width=True,
                        caption=f"{len(faces)} {T['faces_detected']}")
    except Exception as e:
        logger.error(f"åˆ†æé”™è¯¯: {e}")
        st.error(T["error_processing"])

# ----------------- ä¸»ç¨‹åº -----------------
def main():
    st.title(f"ğŸŒ {T['title']}")
    st.caption(T["upload_guide"])

    face_cascade = load_face_cascade()
    if face_cascade is None:
        return

    if "username" not in st.session_state:
        st.session_state.username = ""

    with st.sidebar:
        st.subheader(T["user_auth"])
        username = st.text_input(T["enter_username"], key="username_input")
        if username:
            st.session_state.username = username
            st.success(f"{T['welcome']} {username}")

    with st.expander(T["debug_info"]):
        st.write(f"OpenCV version: {cv2.__version__}")
        st.write(f"Streamlit version: {st.__version__}")
        st.write("Session State:", st.session_state)

    if st.session_state.username:
        uploaded_file = st.file_uploader(T["upload_image"], type=["jpg", "jpeg", "png"])
        if uploaded_file:
            show_analysis_results(uploaded_file, st.session_state.username, face_cascade)
    else:
        st.warning(T["input_username_continue"])

if __name__ == "__main__":
    if not os.path.exists(".streamlit"):
        os.makedirs(".streamlit")
    main()
