import streamlit as st
import cv2
import numpy as np
from PIL import Image
import pandas as pd
from datetime import datetime
import random
import logging
from geopy.geocoders import Nominatim

# ----------------- åˆå§‹åŒ–è®¾ç½® -----------------
st.set_page_config(
    page_title="AIæƒ…ç»ªä¸ä½ç½®æ£€æµ‹ç³»ç»Ÿ",
    page_icon="ğŸŒ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ----------------- å¤šè¯­è¨€æ”¯æŒ -----------------
LANGUAGES = ["ä¸­æ–‡", "English", "Malay"]
lang = st.sidebar.selectbox("ğŸŒ é€‰æ‹©è¯­è¨€", LANGUAGES)

TRANSLATIONS = {
    "ä¸­æ–‡": {
        "title": "AIæƒ…ç»ªä¸ä½ç½®æ£€æµ‹ç³»ç»Ÿ",
        "upload_guide": "ä¸Šä¼ ç…§ç‰‡åˆ†æé¢éƒ¨è¡¨æƒ…å¹¶æ¨æµ‹ä½ç½®",
        "username": "ç”¨æˆ·å",
        "enter_username": "è¾“å…¥ç”¨æˆ·å",
        "welcome": "æ¬¢è¿",
        "upload_image": "ä¸Šä¼ å›¾ç‰‡ (JPG/PNG)",
        "analysis_results": "åˆ†æç»“æœ",
        "detected_emotion": "æ£€æµ‹åˆ°çš„æƒ…ç»ª",
        "estimated_location": "ä¼°è®¡ä½ç½®",
        "download_results": "ä¸‹è½½ç»“æœ",
        "original_image": "åŸå§‹å›¾ç‰‡",
        "processed_image": "å¤„ç†åçš„å›¾ç‰‡",
        "no_faces": "æœªæ£€æµ‹åˆ°äººè„¸",
        "error_processing": "å›¾ç‰‡å¤„ç†é”™è¯¯",
        "debug_info": "è°ƒè¯•ä¿¡æ¯"
    },
    "English": {
        "title": "AI Emotion & Location Detector",
        "upload_guide": "Upload a photo to analyze facial expressions and estimate location",
        "username": "Username",
        "enter_username": "Enter your username",
        "welcome": "Welcome",
        "upload_image": "Upload an image (JPG/PNG)",
        "analysis_results": "Analysis Results",
        "detected_emotion": "Detected Emotion",
        "estimated_location": "Estimated Location",
        "download_results": "Download Results",
        "original_image": "Original Image",
        "processed_image": "Processed Image",
        "no_faces": "No faces detected",
        "error_processing": "Error processing image",
        "debug_info": "Debug Info"
    },
    "Malay": {
        "title": "Sistem Pengesanan Emosi & Lokasi AI",
        "upload_guide": "Muat naik foto untuk analisis ekspresi muka dan anggaran lokasi",
        "username": "Nama pengguna",
        "enter_username": "Masukkan nama pengguna",
        "welcome": "Selamat datang",
        "upload_image": "Muat naik imej (JPG/PNG)",
        "analysis_results": "Keputusan Analisis",
        "detected_emotion": "Emosi yang Dikesan",
        "estimated_location": "Lokasi Dianggarkan",
        "download_results": "Muat Turun Keputusan",
        "original_image": "Imej Asal",
        "processed_image": "Imej Diproses",
        "no_faces": "Tiada muka dikesan",
        "error_processing": "Ralat memproses imej",
        "debug_info": "Maklumat Debug"
    }
}
T = TRANSLATIONS[lang]

# ----------------- åŠ è½½æ¨¡å‹ -----------------
@st.cache_resource
def load_face_cascade():
    try:
        return cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
    except Exception as e:
        logger.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        st.error("æ— æ³•åŠ è½½äººè„¸æ£€æµ‹æ¨¡å‹")
        return None

# ----------------- æ ¸å¿ƒåŠŸèƒ½ -----------------
def detect_faces(img_cv, face_cascade):
    try:
        gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)
        faces = face_cascade.detectMultiScale(gray, 1.1, 4)
        return faces if isinstance(faces, np.ndarray) else np.array([])
    except Exception as e:
        logger.error(f"äººè„¸æ£€æµ‹é”™è¯¯: {e}")
        return np.array([])

def analyze_emotion(faces):
    """ç®€åŒ–ç‰ˆæƒ…ç»ªåˆ†æï¼ˆå®é™…é¡¹ç›®å»ºè®®ç”¨DeepFaceï¼‰"""
    return ["happy" if random.random() > 0.5 else "neutral" for _ in faces]

def estimate_location():
    """éšæœºä½ç½®ç”Ÿæˆï¼ˆå®é™…é¡¹ç›®å¯ç”¨GPSå…ƒæ•°æ®ï¼‰"""
    cities = ["åŒ—äº¬", "ä¸Šæµ·", "å¹¿å·", "æ·±åœ³", "æˆéƒ½"]
    return f"{random.choice(cities)}, ä¸­å›½"

# ----------------- ç•Œé¢ç»„ä»¶ -----------------
def show_analysis_results(uploaded_file, username, face_cascade):
    try:
        img = Image.open(uploaded_file)
        img_cv = np.array(img)
        
        # ç¡®ä¿å›¾åƒä¸º3é€šé“
        if len(img_cv.shape) == 2:
            img_cv = cv2.cvtColor(img_cv, cv2.COLOR_GRAY2BGR)
        elif img_cv.shape[2] == 4:
            img_cv = img_cv[:, :, :3]

        col1, col2 = st.columns([1, 2])

        with col1:
            st.subheader(T["analysis_results"])
            
            faces = detect_faces(img_cv, face_cascade)
            if len(faces) == 0:
                st.warning(T["no_faces"])
                return

            emotions = analyze_emotion(faces)
            location = estimate_location()
            
            st.metric(T["detected_emotion"], ", ".join(emotions))
            st.metric(T["estimated_location"], location)

            # ä¿å­˜ç»“æœ
            save_to_history(username, emotions[0], location)
            
            # ä¸‹è½½æŒ‰é’®
            st.download_button(
                label=T["download_results"],
                data=pd.DataFrame({
                    "æƒ…ç»ª": emotions,
                    "ä½ç½®": [location]*len(emotions)
                }).to_csv(index=False),
                file_name="analysis_results.csv"
            )

        with col2:
            tab1, tab2 = st.tabs([T["original_image"], T["processed_image"]])
            
            with tab1:
                st.image(img, use_column_width=True)
            
            with tab2:
                for (x, y, w, h) in faces:
                    cv2.rectangle(img_cv, (x, y), (x+w, y+h), (0, 255, 0), 2)
                st.image(img_cv, channels="BGR", use_column_width=True)

    except Exception as e:
        logger.error(f"åˆ†æé”™è¯¯: {e}")
        st.error(T["error_processing"])

def save_to_history(username, emotion, location):
    try:
        new_record = pd.DataFrame([{
            "username": username,
            "emotion": emotion,
            "location": location,
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }])
        
        if os.path.exists("history.csv"):
            history = pd.read_csv("history.csv")
            history = pd.concat([history, new_record])
        else:
            history = new_record
            
        history.to_csv("history.csv", index=False)
    except Exception as e:
        logger.error(f"ä¿å­˜å†å²è®°å½•å¤±è´¥: {e}")

# ----------------- ä¸»ç¨‹åº -----------------
def main():
    st.title(f"ğŸŒ {T['title']}")
    st.caption(T["upload_guide"])
    
    face_cascade = load_face_cascade()
    if face_cascade is None:
        return
    
    # ç”¨æˆ·ç™»å½•
    if "username" not in st.session_state:
        st.session_state.username = ""
    
    with st.sidebar:
        username = st.text_input(T["enter_username"], key="username_input")
        if username:
            st.session_state.username = username
            st.success(f"{T['welcome']} {username}")
    
    # è°ƒè¯•ä¿¡æ¯
    with st.expander(T["debug_info"]):
        st.write(f"OpenCVç‰ˆæœ¬: {cv2.__version__}")
        st.write(f"Streamlitç‰ˆæœ¬: {st.__version__}")
        st.write("ä¼šè¯çŠ¶æ€:", st.session_state)
    
    # ä¸»ç•Œé¢
    if st.session_state.username:
        uploaded_file = st.file_uploader(T["upload_image"], type=["jpg", "jpeg", "png"])
        if uploaded_file:
            show_analysis_results(uploaded_file, st.session_state.username, face_cascade)
    else:
        st.warning("è¯·è¾“å…¥ç”¨æˆ·åç»§ç»­")

if __name__ == "__main__":
    import os
    if not os.path.exists(".streamlit"):
        os.makedirs(".streamlit")
    main()
